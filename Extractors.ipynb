{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9de64f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a93ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('dataset1.csv', encoding='cp1251', sep='\\t', header=None)\n",
    "df2 = pd.read_csv('dataset2.csv', encoding='cp1251', sep='\\t', header=None, quoting=3)\n",
    "df = pd.concat([df1, df2], axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df55948e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B057586722045</td>\n",
       "      <td>_ЁЭффективное численное решение задачи Стокса ...</td>\n",
       "      <td>_ЁРассматривается задача Стокса с разрывным ко...</td>\n",
       "      <td>_ЁХабаровск\\_Ёзадача Стокса с разрывным коэффи...</td>\n",
       "      <td>e8\\f2</td>\n",
       "      <td>13Д\\16Б</td>\n",
       "      <td>27.41.19\\30.17.02</td>\n",
       "      <td>271.41.19.17.21\\301.17.02.11</td>\n",
       "      <td>###</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>B10213980294</td>\n",
       "      <td>_ЁАвтоматическая маршрутизация в среде с препя...</td>\n",
       "      <td>_ЁВ работе рассматривается перемещение тела гр...</td>\n",
       "      <td>_Ёавтоматическая маршрутизация\\_Ёинтеллектуаль...</td>\n",
       "      <td>e8\\e1\\e9\\00</td>\n",
       "      <td>93\\93-Y\\37\\37-Y\\РС\\81</td>\n",
       "      <td>28.23.27\\50.41.21\\55.30.31</td>\n",
       "      <td>282.23.27.09\\509.41.21.25.19\\551.30.31.07.13</td>\n",
       "      <td>###</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>B103249601493</td>\n",
       "      <td>Структурно-динамический анализ с помощью ЯМР-р...</td>\n",
       "      <td>Изучение движения молекул и атомов в твердых т...</td>\n",
       "      <td>Татарстан\\ЯМР-релаксометрия\\газы природные\\доб...</td>\n",
       "      <td>e5\\f7</td>\n",
       "      <td>08Д\\19А</td>\n",
       "      <td>31.01.33\\38.57.23</td>\n",
       "      <td>311.01.33\\383.57.23.01</td>\n",
       "      <td>###</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>B10349920193X</td>\n",
       "      <td>Структурно-функциональные исследования пептидо...</td>\n",
       "      <td>Излагается разрабатываемая концепция создания ...</td>\n",
       "      <td>изучение\\лекарственные средства\\пептиды\\разраб...</td>\n",
       "      <td>e3</td>\n",
       "      <td>04Р1\\04Б3</td>\n",
       "      <td>62.13.39</td>\n",
       "      <td>621.13.39</td>\n",
       "      <td>###</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B103499202650</td>\n",
       "      <td>Применение хроматографии и масс-спектрометрии ...</td>\n",
       "      <td>В результате проведенных исследований разработ...</td>\n",
       "      <td>Galleria mellonella\\антибактериальная активнос...</td>\n",
       "      <td>e3</td>\n",
       "      <td>04Р1\\04Б3</td>\n",
       "      <td>62.13.39</td>\n",
       "      <td>621.13.39</td>\n",
       "      <td>###</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index              0                                                  1  \\\n",
       "0      0  B057586722045  _ЁЭффективное численное решение задачи Стокса ...   \n",
       "1      1   B10213980294  _ЁАвтоматическая маршрутизация в среде с препя...   \n",
       "2      2  B103249601493  Структурно-динамический анализ с помощью ЯМР-р...   \n",
       "3      3  B10349920193X  Структурно-функциональные исследования пептидо...   \n",
       "4      4  B103499202650  Применение хроматографии и масс-спектрометрии ...   \n",
       "\n",
       "                                                   2  \\\n",
       "0  _ЁРассматривается задача Стокса с разрывным ко...   \n",
       "1  _ЁВ работе рассматривается перемещение тела гр...   \n",
       "2  Изучение движения молекул и атомов в твердых т...   \n",
       "3  Излагается разрабатываемая концепция создания ...   \n",
       "4  В результате проведенных исследований разработ...   \n",
       "\n",
       "                                                   3            4  \\\n",
       "0  _ЁХабаровск\\_Ёзадача Стокса с разрывным коэффи...        e8\\f2   \n",
       "1  _Ёавтоматическая маршрутизация\\_Ёинтеллектуаль...  e8\\e1\\e9\\00   \n",
       "2  Татарстан\\ЯМР-релаксометрия\\газы природные\\доб...        e5\\f7   \n",
       "3  изучение\\лекарственные средства\\пептиды\\разраб...           e3   \n",
       "4  Galleria mellonella\\антибактериальная активнос...           e3   \n",
       "\n",
       "                       5                           6  \\\n",
       "0                13Д\\16Б           27.41.19\\30.17.02   \n",
       "1  93\\93-Y\\37\\37-Y\\РС\\81  28.23.27\\50.41.21\\55.30.31   \n",
       "2                08Д\\19А           31.01.33\\38.57.23   \n",
       "3              04Р1\\04Б3                    62.13.39   \n",
       "4              04Р1\\04Б3                    62.13.39   \n",
       "\n",
       "                                              7    8  \n",
       "0                  271.41.19.17.21\\301.17.02.11  ###  \n",
       "1  282.23.27.09\\509.41.21.25.19\\551.30.31.07.13  ###  \n",
       "2                        311.01.33\\383.57.23.01  ###  \n",
       "3                                     621.13.39  ###  \n",
       "4                                     621.13.39  ###  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18acb3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = open('viniti_md.txt','r',encoding='cp1251',)\n",
    "tx = txt.readlines()\n",
    "alphabet = []\n",
    "for x in tx:\n",
    "    alphabet.append(x.strip('\\n').split('\\t'))\n",
    "    \n",
    "alpha_df = pd.DataFrame(alphabet, columns=['символ',\"значение\", \"код\", \"категория\"])\n",
    "\n",
    "def valid_alpha(grp:list) -> list:\n",
    "    unvalid_alpha = alpha_df.copy()\n",
    "    unvalid_alpha.drop(unvalid_alpha.index[unvalid_alpha['категория'].isin(grp)], inplace=True)\n",
    "    return sorted(unvalid_alpha['символ'], key=lambda x: len(x), reverse=True)\n",
    "\n",
    "unvalid_alpha = valid_alpha(['буквы лат.','цифры','буквы рус.', 'пробел'])\n",
    "for allowed_el in ['-', '.', '!', ',', ':', ';', '?']:\n",
    "    unvalid_alpha.remove(allowed_el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e64bf01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(unvalid_alpha: list, s: str)->str:\n",
    "    current_str = s\n",
    "    for x in unvalid_alpha:\n",
    "        current_str = current_str.replace(x, ' ')\n",
    "    tokens = current_str.split(' ')\n",
    "    current_str = ' '.join([token for token in tokens if token != ''])\n",
    "        \n",
    "    return current_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7646bd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 50.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "name = 1\n",
    "anot = 2\n",
    "keywords = 3\n",
    "\n",
    "df['keywords'] = df[keywords].apply(lambda x: list(map(lambda y: text_processing(unvalid_alpha, y), x.split('\\\\'))))\n",
    "df['name'] = df[name].apply(lambda x: text_processing(unvalid_alpha, x))\n",
    "df['anot'] = df[anot].apply(lambda x: text_processing(unvalid_alpha, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3544eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>name</th>\n",
       "      <th>anot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Хабаровск, задача Стокса с разрывным коэффици...</td>\n",
       "      <td>Эффективное численное решение задачи Стокса с ...</td>\n",
       "      <td>Рассматривается задача Стокса с разрывным коэф...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[автоматическая маршрутизация, интеллектуальны...</td>\n",
       "      <td>Автоматическая маршрутизация в среде с препятс...</td>\n",
       "      <td>В работе рассматривается перемещение тела груп...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Татарстан, ЯМР-релаксометрия, газы природные,...</td>\n",
       "      <td>Структурно-динамический анализ с помощью ЯМР-р...</td>\n",
       "      <td>Изучение движения молекул и атомов в твердых т...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[изучение, лекарственные средства, пептиды, ра...</td>\n",
       "      <td>Структурно-функциональные исследования пептидо...</td>\n",
       "      <td>Излагается разрабатываемая концепция создания ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Galleria mellonella, антибактериальная активн...</td>\n",
       "      <td>Применение хроматографии и масс-спектрометрии ...</td>\n",
       "      <td>В результате проведенных исследований разработ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            keywords  \\\n",
       "0  [Хабаровск, задача Стокса с разрывным коэффици...   \n",
       "1  [автоматическая маршрутизация, интеллектуальны...   \n",
       "2  [Татарстан, ЯМР-релаксометрия, газы природные,...   \n",
       "3  [изучение, лекарственные средства, пептиды, ра...   \n",
       "4  [Galleria mellonella, антибактериальная активн...   \n",
       "\n",
       "                                                name  \\\n",
       "0  Эффективное численное решение задачи Стокса с ...   \n",
       "1  Автоматическая маршрутизация в среде с препятс...   \n",
       "2  Структурно-динамический анализ с помощью ЯМР-р...   \n",
       "3  Структурно-функциональные исследования пептидо...   \n",
       "4  Применение хроматографии и масс-спектрометрии ...   \n",
       "\n",
       "                                                anot  \n",
       "0  Рассматривается задача Стокса с разрывным коэф...  \n",
       "1  В работе рассматривается перемещение тела груп...  \n",
       "2  Изучение движения молекул и атомов в твердых т...  \n",
       "3  Излагается разрабатываемая концепция создания ...  \n",
       "4  В результате проведенных исследований разработ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleared = df[['keywords', 'name', 'anot']]\n",
    "df_cleared.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c1223",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleared['name_anot'] = df_cleared.apply(lambda x: x[1]+'. '+ x[2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f885db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp = df_cleared.sample(10000).reset_index()\n",
    "df_exp.to_csv('df_exp.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3567d1",
   "metadata": {},
   "source": [
    "### Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e0814e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ilya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ilya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from rake_nltk import Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5130dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stopwords_list(add_external=True):\n",
    "    nltk_list = nltk.corpus.stopwords.words('russian') \n",
    "    with open('stopwords-ru.txt', 'r', encoding='utf-8') as f:\n",
    "        external_list = f.read().split('\\n')\n",
    "    final_list = list(set(nltk_list) | set(external_list)) if add_external == True else nltk_list\n",
    "        \n",
    "    return final_list\n",
    "\n",
    "russian_stopwords = get_stopwords_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b1015d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keyphrases(text, model, n_words=5):\n",
    "    if model == 'RAKE':\n",
    "        rake.extract_keywords_from_text(text)\n",
    "        keyphrases = rake.get_ranked_phrases()[:n_words]\n",
    "        \n",
    "    if model == 'YAKE':\n",
    "        keyphrases = list(map(lambda x: x[0], yake.extract_keywords(text)))\n",
    "    \n",
    "    return keyphrases[:n_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "4f6533c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rake = Rake(stopwords=russian_stopwords, max_length=3)\n",
    "df_exp['keyw_RAKE'] = df_exp['name_anot'].apply(lambda x: predict_keyphrases(x, 'RAKE', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "4000d711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "def stem_phrase(phrase):\n",
    "    stemmer = SnowballStemmer(\"russian\")  \n",
    "    words = phrase.lower().split(' ')\n",
    "    stemmed_phrase = ' '.join([stemmer.stem(word) for word in words])\n",
    "    \n",
    "    return stemmed_phrase\n",
    "\n",
    "def check_occurence(check_phrase, phrases_list):\n",
    "    for phrase in phrases_list:\n",
    "        k = 0\n",
    "        phrase_granulated = set(phrase.split(' '))\n",
    "        check_phrase_granulated = check_phrase.split(' ')\n",
    "        for check_word in check_phrase_granulated:\n",
    "            if check_word in phrase_granulated:\n",
    "                k += 1\n",
    "        if k/len(check_phrase_granulated) > 0.5:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "    \n",
    "def keywords_precision_score(keyw_true, keyw_pred, k=5):\n",
    "    if len(keyw_true) == 0 or len(keyw_pred) == 0:\n",
    "        return 0\n",
    "        \n",
    "    n = 0\n",
    "    keyw_true = [stem_phrase(phrase) for phrase in keyw_true]\n",
    "    keyw_pred = [stem_phrase(phrase) for phrase in keyw_pred[:k]]\n",
    "        \n",
    "    for keyw in keyw_pred:\n",
    "        if check_occurence(keyw, keyw_true): \n",
    "            n+=1\n",
    "    \n",
    "    return n/k\n",
    "\n",
    "def keywords_recall_score(keyw_true, keyw_pred, k=5):\n",
    "    if len(keyw_true) == 0 or len(keyw_pred) == 0:\n",
    "        return 0\n",
    "    \n",
    "    n_match = 0\n",
    "    n_true = len(keyw_true)\n",
    "    keyw_true = [stem_phrase(phrase) for phrase in keyw_true]\n",
    "    keyw_pred = [stem_phrase(phrase) for phrase in keyw_pred[:k]]\n",
    "        \n",
    "    for keyw in keyw_true:\n",
    "        if check_occurence(keyw, keyw_pred): \n",
    "            n_match += 1\n",
    "    \n",
    "    return n_match/n_true\n",
    "\n",
    "def keywords_mean_reciprocal_rank(keyw_true, keyw_pred, k=5):\n",
    "    if len(keyw_true) == 0 or len(keyw_pred) == 0:\n",
    "        return 0\n",
    "    \n",
    "    n = 0\n",
    "    keyw_true = [stem_phrase(phrase) for phrase in keyw_true]\n",
    "    keyw_pred = [stem_phrase(phrase) for phrase in keyw_pred[:k]]\n",
    "        \n",
    "    for n_el, keyw in enumerate(keyw_pred):\n",
    "        if check_occurence(keyw, keyw_true): \n",
    "            n = n_el + 1\n",
    "            break\n",
    "    \n",
    "    return 1/n if n != 0 else 0\n",
    "\n",
    "def keywords_mean_average_precision(keyw_true, keyw_pred, k):\n",
    "    if len(keyw_true) == 0 or len(keyw_pred) == 0:\n",
    "        return 0\n",
    "    \n",
    "    idxs = []\n",
    "    keyw_true = [stem_phrase(phrase) for phrase in keyw_true]\n",
    "    keyw_pred = [stem_phrase(phrase) for phrase in keyw_pred[:k]]\n",
    "        \n",
    "    for n_el, keyw in enumerate(keyw_pred):\n",
    "        if check_occurence(keyw, keyw_true):\n",
    "            idxs.append(n_el + 1)\n",
    "            \n",
    "    if len(idxs) == 0:\n",
    "        return 0\n",
    "    \n",
    "    precisions = [(n_el+1)/ idx for n_el, idx in enumerate(idxs)]\n",
    "    return sum(precisions)/len(precisions)\n",
    "\n",
    "def keywords_stem(keyw_true, keyw_pred, k=5):\n",
    "    n = 0\n",
    "    keyw_true = [stem_phrase(phrase) for phrase in keyw_true]\n",
    "    keyw_pred = [stem_phrase(phrase) for phrase in keyw_pred[:k]]\n",
    "    \n",
    "    return keyw_true, keyw_pred\n",
    "\n",
    "def evaluate_extractor(y_true, y_pred, metric, k=5):\n",
    "    metric_values = [] \n",
    "    \n",
    "    try:\n",
    "        if metric == 'precision':\n",
    "            for idx in range(len(y_true)):\n",
    "                value = keywords_precision_score(y_true[idx], y_pred[idx], k)\n",
    "                metric_values.append(value)\n",
    "\n",
    "        if metric == 'recall':\n",
    "            for idx in range(len(y_true)):\n",
    "                value = keywords_recall_score(y_true[idx], y_pred[idx], k)\n",
    "                metric_values.append(value)\n",
    "\n",
    "        if metric == 'MRR':\n",
    "            for idx in range(len(y_true)):\n",
    "                value = keywords_mean_reciprocal_rank(y_true[idx], y_pred[idx], k)\n",
    "                metric_values.append(value)\n",
    "\n",
    "        if metric == 'MAP':\n",
    "            for idx in range(len(y_true)):\n",
    "                value = keywords_mean_average_precision(y_true[idx], y_pred[idx], k)\n",
    "                metric_values.append(value)\n",
    "            \n",
    "        return np.mean(metric_values)\n",
    "    \n",
    "    except KeyError:\n",
    "        print(y_true[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "150947cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction_evaluation_report(df, keyw_true_col, models, metrics, size=0.1):\n",
    "    result = dict()\n",
    "    df = df.sample(round(size*len(df))).reset_index()\n",
    "    \n",
    "    for model_name in models:\n",
    "        pred_column = 'keyw_' + model_name\n",
    "        metrics_values = dict()\n",
    "        for metric_name in metrics:\n",
    "            metrics_values[metric_name+'_at_5'] = evaluate_extractor(df[keyw_true_col], df[pred_column], metric_name, k=5)\n",
    "            metrics_values[metric_name+'_at_10'] = evaluate_extractor(df[keyw_true_col], df[pred_column], metric_name, k=10)\n",
    "        \n",
    "        result[model_name] = metrics_values\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9227e7b",
   "metadata": {},
   "source": [
    "### !pip install yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "1d5a99a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake\n",
    "\n",
    "yake = yake.KeywordExtractor (\n",
    "    lan = \"ru\",     # язык\n",
    "    n = 3,          # максимальное количество слов в фразе\n",
    "    dedupLim = 0.3, # порог похожести слов\n",
    "    top = 10        # количество ключевых слов\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "98e914ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_exp['keyw_YAKE'] = df_exp['name_anot'].apply(lambda x: predict_keyphrases(x, 'YAKE', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "001a3ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = extraction_evaluation_report(df_exp,\n",
    "                                           'keywords',\n",
    "                                           ['RAKE', 'YAKE'],\n",
    "                                           ['precision', 'recall', 'MRR', 'MAP'],\n",
    "                                           size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "495c0db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extractor: RAKE\n",
      "\t precision_at_5 : 0.103\n",
      "\t precision_at_10 : 0.085\n",
      "\t recall_at_5 : 0.174\n",
      "\t recall_at_10 : 0.24\n",
      "\t MRR_at_5 : 0.196\n",
      "\t MRR_at_10 : 0.213\n",
      "\t MAP_at_5 : 0.194\n",
      "\t MAP_at_10 : 0.206\n",
      "Extractor: YAKE\n",
      "\t precision_at_5 : 0.242\n",
      "\t precision_at_10 : 0.201\n",
      "\t recall_at_5 : 0.329\n",
      "\t recall_at_10 : 0.397\n",
      "\t MRR_at_5 : 0.426\n",
      "\t MRR_at_10 : 0.445\n",
      "\t MAP_at_5 : 0.406\n",
      "\t MAP_at_10 : 0.387\n"
     ]
    }
   ],
   "source": [
    "for model in eval_result.keys():\n",
    "    print(\"Extractor:\", model)\n",
    "    for metric in eval_result[model].keys():\n",
    "        print('\\t', metric, \":\", round(eval_result[model][metric], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "e837c23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('eval_result.json', 'w') as fp:\n",
    "    json.dump(eval_result, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afa1dd9",
   "metadata": {},
   "source": [
    "### !pip install summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "7f3f99d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from summa import keywords\n",
    "\n",
    "def predict_keyphrases(text, model, n_words=5):\n",
    "    if model == 'RAKE':\n",
    "        rake.extract_keywords_from_text(text)\n",
    "        keyphrases = rake.get_ranked_phrases()\n",
    "        \n",
    "    if model == 'YAKE':\n",
    "        keyphrases = list(map(lambda x: x[0], yake.extract_keywords(text)))\n",
    "        \n",
    "    if model == 'TextRank':\n",
    "        cleaned_text = ' '.join([word.replace('\\n', '') for word in text.split(' ') if word.lower() not in russian_stopwords])\n",
    "        keyphrases = keywords.keywords(text, language = \"russian\").split(\"\\n\")\n",
    "    \n",
    "    return keyphrases[:n_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "a9336175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_exp['keyw_TextRank'] = df_exp['name_anot'].apply(lambda x: predict_keyphrases(x, 'TextRank', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "31ac056f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eval_result = extraction_evaluation_report(df_exp,\n",
    "                                           'keywords',\n",
    "                                           ['TextRank'],\n",
    "                                           ['precision', 'recall', 'MRR', 'MAP'],\n",
    "                                           size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "c4bfd0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extractor: TextRank\n",
      "\t precision_at_5 : 0.272\n",
      "\t precision_at_10 : 0.212\n",
      "\t recall_at_5 : 0.099\n",
      "\t recall_at_10 : 0.143\n",
      "\t MRR_at_5 : 0.404\n",
      "\t MRR_at_10 : 0.422\n",
      "\t MAP_at_5 : 0.409\n",
      "\t MAP_at_10 : 0.417\n"
     ]
    }
   ],
   "source": [
    "for model in eval_result.keys():\n",
    "    print(\"Extractor:\", model)\n",
    "    for metric in eval_result[model].keys():\n",
    "        print('\\t', metric, \":\", round(eval_result[model][metric], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3e6f70",
   "metadata": {},
   "source": [
    "### KeyBert - DeepPavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b064b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keyphrase-vectorizers --user\n",
    "#!pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "674c8d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "783b85be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp_bert = df_cleared.sample(1000).reset_index()\n",
    "df_exp_bert.to_csv('df_exp_bert.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a614a4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\Ilya/.cache\\torch\\sentence_transformers\\DeepPavlov_rubert-base-cased-sentence. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "bert_kw = KeyBERT(model='DeepPavlov/rubert-base-cased-sentence')\n",
    "#bert_kw = KeyBERT(model='miemBertProject/miem-scibert-linguistic') \n",
    "#bert_kw = KeyBERT(model='paraphrase-multilingual-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b2c97a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keyphrases(text, model, n_words=5):\n",
    "    if model == 'RAKE':\n",
    "        rake.extract_keywords_from_text(text)\n",
    "        keyphrases = rake.get_ranked_phrases()\n",
    "        \n",
    "    if model == 'YAKE':\n",
    "        keyphrases = list(map(lambda x: x[0], yake.extract_keywords(text)))\n",
    "        \n",
    "    if model == 'TextRank':\n",
    "        cleaned_text = ' '.join([word.replace('\\n', '') for word in text.split(' ') if word.lower() not in russian_stopwords])\n",
    "        keyphrases = keywords.keywords(text, language = \"russian\").split(\"\\n\")\n",
    "        \n",
    "    if model == 'BERT_spacy':\n",
    "        vectorizer = KeyphraseCountVectorizer(spacy_pipeline=\"ru_core_news_sm\",\n",
    "                                              stop_words=russian_stopwords,\n",
    "                                              pos_pattern='<ADJ.*>*<N.*>+')\n",
    "        bert_keywords = kw_model.extract_keywords(docs=text,\n",
    "                                                  vectorizer=vectorizer,\n",
    "                                                  nr_candidates=20,\n",
    "                                                  top_n=10,\n",
    "                                                  use_mmr=True,\n",
    "                                                  diversity=0.3,\n",
    "                                                 )\n",
    "        keyphrases = list(map(lambda x: x[0], bert_keywords))\n",
    "        \n",
    "    if model == 'BERT_sklearn':\n",
    "        bert_keywords = kw_model.extract_keywords(docs=text,\n",
    "                                                  keyphrase_ngram_range=(1,3),\n",
    "                                                  stop_words=russian_stopwords,\n",
    "                                                  nr_candidates=20,\n",
    "                                                  top_n=10,\n",
    "                                                  use_mmr=True,\n",
    "                                                  diversity=0.3)\n",
    "        keyphrases = list(map(lambda x: x[0], bert_keywords))\n",
    "    \n",
    "    return keyphrases[:n_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a8759745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 35min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_exp_bert['keyw_BERT_spacy'] = df_exp_bert['name_anot'].apply(lambda x: predict_keyphrases(x, 'BERT_spacy', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4477e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_exp_bert['keyw_BERT_sklearn'] = df_exp_bert['name_anot'].apply(lambda x: predict_keyphrases(x, 'BERT_sklearn', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa90eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eval_result = extraction_evaluation_report(df_exp_bert,\n",
    "                                           'keywords',\n",
    "                                           ['BERT_spacy', 'BERT_sklearn'],\n",
    "                                           ['precision', 'recall', 'MRR', 'MAP'],\n",
    "                                           size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00061e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in eval_result.keys():\n",
    "    print(\"Extractor:\", model)\n",
    "    for metric in eval_result[model].keys():\n",
    "        print('\\t', metric, \":\", round(eval_result[model][metric], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5791578b",
   "metadata": {},
   "source": [
    "### KeyBert - MiemLinguistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9b4e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_kw = KeyBERT(model='miemBertProject/miem-scibert-linguistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b909d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_exp_bert['keyw_BERT_spacy'] = df_exp_bert['name_anot'].apply(lambda x: predict_keyphrases(x, 'BERT_spacy', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30eade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_exp_bert['keyw_BERT_sklearn'] = df_exp_bert['name_anot'].apply(lambda x: predict_keyphrases(x, 'BERT_sklearn', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addb0281",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eval_result = extraction_evaluation_report(df_exp_bert,\n",
    "                                           'keywords',\n",
    "                                           ['BERT_spacy', 'BERT_sklearn'],\n",
    "                                           ['precision', 'recall', 'MRR', 'MAP'],\n",
    "                                           size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2de8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in eval_result.keys():\n",
    "    print(\"Extractor:\", model)\n",
    "    for metric in eval_result[model].keys():\n",
    "        print('\\t', metric, \":\", round(eval_result[model][metric], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db89141e",
   "metadata": {},
   "source": [
    "### KeyBert paraphrase-multilingual-MiniLM-L12-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1d56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_kw = KeyBERT(model='paraphrase-multilingual-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94e8071",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_exp_bert['keyw_BERT_spacy'] = df_exp_bert['name_anot'].apply(lambda x: predict_keyphrases(x, 'BERT_spacy', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e870cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_exp_bert['keyw_BERT_sklearn'] = df_exp_bert['name_anot'].apply(lambda x: predict_keyphrases(x, 'BERT_sklearn', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d322800",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eval_result = extraction_evaluation_report(df_exp_bert,\n",
    "                                           'keywords',\n",
    "                                           ['BERT_spacy', 'BERT_sklearn'],\n",
    "                                           ['precision', 'recall', 'MRR', 'MAP'],\n",
    "                                           size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9396a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in eval_result.keys():\n",
    "    print(\"Extractor:\", model)\n",
    "    for metric in eval_result[model].keys():\n",
    "        print('\\t', metric, \":\", round(eval_result[model][metric], 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
